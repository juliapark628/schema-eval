---
title: "Florida LSNF Website Analysis"
author: "Julia Park"
date: "`r Sys.Date()`"
output:
  github_document:
    toc: true
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
```

```{r message=FALSE, warning=FALSE}
# Libraries
library(tidyverse)
library(readxl)
library(lubridate)

# Parameters
# change this to your directory
setwd("~/GitHub/Lab_Legal_Design/schema_eval/data")

file_daily_visitors = "Florida_LSNF/visitors-daily-count.xlsx"
file_weekly_visitors = "Florida_LSNF/visitors-overview-total.xlsx"
file_engagement_depth = "Florida_LSNF/visitors-engagement-depth.xlsx"
file_engagement_duration = "Florida_LSNF/visitors-engagement-duration.xlsx"
file_freq_interval = "Florida_LSNF/visitors-frequency-recency-interval.xlsx"
file_freq_session_count = "Florida_LSNF/visitors-frequency-recency-session-count.xlsx"

#multi vs single
file_session_type = "Florida_LSNF/visitors-overview-session-type.xlsx" 

#direct vs search vs organic
file_traffic_type = "Florida_LSNF/visitors-overview-traffic-type.xlsx"

file_engagement_duration_timeseries = "Florida_LSNF/visitors-duration-timeseries.rds"

file_search_performance = "Florida_LSNF/search-performance.xlsx" 

file_landing_pages = "Florida_LSNF/acquisition-sc-landingpages.xlsx"
file_queries = "Florida_LSNF/acquisition-sc-queries.xlsx"

#===============================================================================

# Code
string_2019 <- "Jan 1, 2019 - Jul 30, 2019"
string_2020 <- "Jan 1, 2020 - Jul 30, 2020"
schema_week <- 18 # 5/11/2020
schema_date <- as.POSIXct(as.Date("2020-05-11"))
daily_visitors <- read_excel(file_daily_visitors, sheet = "Dataset1")
weekly_visitors <- read_excel(file_weekly_visitors, sheet = "Dataset1")
engagement_depth <- read_excel(file_engagement_depth)
engagement_duration <- read_excel(file_engagement_duration)
freq_interval <- read_excel(file_freq_interval)
freq_session_count <- read_excel(file_freq_session_count)
session_type <- read_excel(file_session_type)
traffic_type <- read_excel(file_traffic_type)
landing_pages <- read_excel(file_landing_pages)
queries <- read_excel(file_queries)
engagement_duration_timeseries <- read_rds(file_engagement_duration_timeseries) %>% filter(week_index != 0)
dates <- read_excel(file_search_performance, sheet = "Dates")

```


## Visitors

```{r}
x_labels <- function(x) {
 case_when(
  x == 0 ~ "January", 
  x == 9 ~ "March", 
  x == 17 ~ "May", 
  x == 26 ~ "July", 
  x == 35 ~ "September", 
 )
}

x_breaks <- c(0, 9, 17, 26, 35)
```



```{r}
weekly_visitors %>% 
  filter(`Week Index` != 43) %>% 
  filter(`Week Index` != 0) %>% 
  ggplot(aes(x = `Week Index`, y = Users, color = `Date Range`)) +
  geom_line() + 
  geom_vline(aes(xintercept = schema_week)) +
  geom_smooth() +
  scale_x_continuous(
    breaks = x_breaks, 
    labels = x_labels
  ) +
  labs(
    title = "Florida LSNF: 2020 vs 2019 weekly Visitors", 
    subtitle = "2020's visitor trend before schema implemetation differs drastically from last year"
  ) + 
  theme_minimal()
```

## Traffic Type
```{r}
traffic_type %>% 
  filter(`Date Range` == string_2019) %>% 
  filter(`Week Index` != 30) %>% 
  filter(`Week Index` != 0) %>% 
  filter(Segment != "All Users") %>% 
  filter(Segment != "Organic Traffic") %>% 
  ggplot(aes(x = `Week Index`, y = Users, color = Segment)) +
  geom_line() + 
  scale_x_continuous(
    breaks = x_breaks, 
    labels = x_labels
  ) +
  labs(
    title = "2019 traffic sources: direct and search traffic contribution proportions are consistent"
  ) + 
  theme_minimal() 
```


```{r}
traffic_type %>% 
  filter(`Date Range` == string_2020) %>% 
  filter(`Week Index` != 0) %>% 
  filter(Segment != "All Users") %>% 
  filter(Segment != "Organic Traffic") %>% 
  ggplot(aes(x = `Week Index`, y = Users, color = Segment)) +
  geom_line() + 
  geom_vline(xintercept = 18) +
  scale_x_continuous(
    breaks = x_breaks, 
    labels = x_labels
  ) +
  labs(
    title = "2020 traffic sources: after schema implementation, search contributes more visitors", 
    subtitle = "Proportional decrease in direct traffic may indicate other technical causes of shift"
  ) +
 theme_minimal()
```

## Duration

```{r}
new_engagement_duration_timeseries <-
 engagement_duration_timeseries %>% 
 mutate(
  `Session Duration` = fct_collapse(`Session Duration`, 
     `0 - 10 seconds` = c("0-10 seconds"), 
     `10 sec - 1 min` = c("11-30 seconds", "31-60 seconds"),
     `1 min - 10 min` = c("61-180 seconds", "181-600 seconds"), 
     `10 min - 30 min` = c("601-1800 seconds"), 
     `30+ min` = c("1801+ seconds")
   ), 
  `Session Duration` = fct_relevel(`Session Duration`, "0 - 10 seconds", "10 sec - 1 min", "1 min - 10 min", "10 min - 30 min", "30+ min")
 ) %>% 
 group_by(`Session Duration`, week_index) %>% 
 summarize(
  Sessions = sum(Sessions), 
  Pageviews = sum(Pageviews)
 ) %>% 
 ungroup() %>% 
 filter(`Session Duration` != "Total")

```


```{r}
new_engagement_duration_timeseries %>% 
  filter(`Session Duration` != "Total") %>% 
  ggplot(aes(x = week_index, y = Sessions, color = `Session Duration`)) + 
  geom_line() + 
  geom_vline(xintercept = 18) + 
  scale_x_continuous(
    breaks = x_breaks, 
    labels = x_labels
  ) +
  labs(
   title = "Florida LSNF: Session duration fairly stable over time", 
   subtitle = "1 to 10 minute sessions slightly on the rise",
   x = "Week Index"
  ) +
  theme_minimal() 
```


```{r}
new_engagement_duration_timeseries %>% 
  mutate(
    pageview_per_session = Pageviews / Sessions
  ) %>% 
  filter(`Session Duration` != "Total") %>% 
  ggplot(aes(x = week_index, y = pageview_per_session, color = `Session Duration`)) + 
  geom_line() + 
  geom_vline(xintercept = 18) + 
  scale_x_continuous(
    breaks = x_breaks, 
    labels = x_labels
  ) +
  labs(
   title = "Florida LSNF: Pageview per session also stable over time", 
   x = "Week Index", 
   y = "Pageview per session"
  ) +
  theme_minimal()
```


# Search Performance

```{r}
# Search Console vs Google Analytics 
# dates %>% 
#   left_join(daily_visitors, by = c("Date" = "Day Index")) %>% 
#   mutate(
#     difference = Users - Clicks,
#     week = week(Date)
#   ) %>% 
#   drop_na() %>% 
#   group_by(week) %>% 
#   summarize(value = sum(difference)) %>% 
#   ggplot(aes(x = week, y = value)) + 
#   geom_line() +
#     scale_x_continuous(
#     breaks = x_breaks, 
#     labels = x_labels
#   ) + 
#   labs(
#     title = "Florida LSNF: difference between Search Console clicks and"
#   )
```


```{r}
dates %>% 
 ggplot(aes(x = Date, y = Clicks)) + 
 geom_line() + 
 geom_vline(xintercept = schema_date, color = "red") +
 geom_smooth(method = "loess") + 
 labs(
  title = "Florida LSNF: 2020 daily clicks (from Search Console)",
  subtitle = "Increases after schema implementation, but 2019 data shows that visitor counts \nusually increase at end of year"
 ) + 
 theme_minimal()
```


```{r}
dates %>% 
 ggplot(aes(x = Date, y = CTR)) + 
 geom_line() + 
 geom_vline(xintercept = schema_date, color = "red") +
 geom_smooth(method = "loess") + 
 labs(
  title = "Florida LSNF: 2020 click-through rate", 
  subtitle = "CTR improved in October \nincrease in March/April due to lower impressions"
 ) + 
 theme_minimal()
```


```{r}
dates %>% 
 ggplot(aes(x = Date, y = `Position`)) + 
 geom_line() + 
 geom_vline(xintercept = schema_date, color = "red") +
 geom_smooth(method = "loess") + 
 scale_y_reverse() +
 labs(
  title = "Florida LSNF: 2020 average search result ranking",
  subtitle = "Improvement in ranking after June: the result of schema or seasonal increase in visitors?"
 ) + 
 theme_minimal()
```


## Search Check:
```{r}
total_direct_search_clicks <- 
 queries %>% 
 filter(str_detect(`Date Range`, "2020")) %>% 
 filter(`Search Query` != "legal services" || `Search Query` != "legal aid" || `Search Query` != "legal aid tallahassee") %>% 
 drop_na() %>% 
 summarize(
  total_direct_search_clicks = sum(Clicks)
 )
total_direct_search_clicks
```

```{r}
total_clicks <- 6274
total_clicks
```

```{r}
total_direct_search_clicks / total_clicks
```

## Recommendations

Pages with high Click rate, but low CTR: 

```{r}
landing_pages %>% 
 filter(str_detect(`Date Range`, "2020")) %>% 
 filter(`Landing Page` != "Total") %>% 
 top_n(5, wt = Clicks) %>% 
 arrange(`CTR`) %>% 
 select(`Landing Page`, CTR, Clicks)
```

Highest CTR: 

```{r}
landing_pages %>% 
 filter(str_detect(`Date Range`, "2020")) %>% 
 filter(`Landing Page` != "Total") %>% 
 top_n(5, wt = CTR) %>% 
 arrange(desc(`CTR`)) %>% 
 select(`Landing Page`, CTR)
```

Highest Impression count: 

```{r}
landing_pages %>% 
 filter(str_detect(`Date Range`, "2020")) %>% 
 filter(`Landing Page` != "Total") %>% 
 top_n(5, wt = Impressions) %>% 
 arrange(desc(`Impressions`)) %>% 
 select(`Landing Page`, Impressions)
```

Highest Page-per-session count: 

```{r}
landing_pages %>% 
 filter(str_detect(`Date Range`, "2020")) %>% 
 filter(`Landing Page` != "Total") %>% 
 top_n(5, wt = `Pages / Session`) %>% 
 arrange(desc(`Pages / Session`)) %>% 
 select(`Landing Page`, `Pages / Session`)
```

```{r}
landing_pages %>% 
 filter(str_detect(`Date Range`, "2020")) %>% 
 filter(`Landing Page` != "Total") %>% 
 top_n(5, wt = `Clicks`) %>% 
 arrange(desc(`Clicks`)) %>% 
 select(`Landing Page`, `Clicks`)
```

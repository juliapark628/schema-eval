---
title: "Idaho Legal Aid Website Analysis"
author: "Julia Park"
date: "`r Sys.Date()`"
output:
  github_document:
    toc: true
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
```

```{r message=FALSE, warning=FALSE}
# Libraries
library(tidyverse)
library(readxl)
library(lubridate)

# Parameters
# change this to your data directory
setwd("~/GitHub/Lab_Legal_Design/schema_eval/data")

file_daily_visitors = "Idaho/visitors-daily-count.xlsx"
file_weekly_visitors = "Idaho/visitors-overview-total.xlsx"
file_engagement_depth = "Idaho/visitors-engagement-depth.xlsx"
file_engagement_duration = "Idaho/visitors-engagement-duration.xlsx"
file_freq_interval = "Idaho/visitors-frequency-recency-interval.xlsx"
file_freq_session_count = "Idaho/visitors-frequency-recency-session-count.xlsx"

#multi vs single
file_session_type = "Idaho/visitors-overview-session-type.xlsx" 

#direct vs search vs organic
file_traffic_type = "Idaho/visitors-overview-traffic-type.xlsx"

file_search_result_performance = "Idaho/search_result_performance.rds"
file_engagement_duration_timeseries = "Idaho/visitors-duration-timeseries.rds"
file_session_type_timeseries = "Idaho/visitors-session-type-timeseries.rds"

file_landing_pages = "Idaho/acquisition-sc-landingpages.xlsx"
file_queries = "Idaho/acquisition-sc-queries.xlsx"

#===============================================================================

# Code
schema_week <- 19 # 5/6/2020
schema_date <-  as.POSIXct(as.Date("2020-05-06"))

string_2019 <- "Jan 1, 2019 - Oct 27, 2019"
string_2020 <- "Jan 1, 2020 - Oct 27, 2020"
daily_visitors_2019 <- read_excel(file_daily_visitors, sheet = "Dataset1") %>% filter(`Date Range` == string_2019)
daily_visitors_2020 <- read_excel(file_daily_visitors, sheet = "Dataset1") %>% filter(`Date Range` == string_2020)
weekly_visitors <- read_excel(file_weekly_visitors, sheet = "Dataset1")
engagement_depth <- read_excel(file_engagement_depth)
engagement_duration <- read_excel(file_engagement_duration)
freq_interval <- read_excel(file_freq_interval)
freq_session_count <- read_excel(file_freq_session_count)
session_type <- read_excel(file_session_type)
traffic_type <- read_excel(file_traffic_type)
landing_pages <- read_excel(file_landing_pages)
queries <- read_excel(file_queries)


search_result_performance <- read_rds(file_search_result_performance)
engagement_duration_timeseries <- read_rds(file_engagement_duration_timeseries)
session_type_timeseries <- read_rds(file_session_type_timeseries)
```

## Visitors

```{r}
daily_visitors_2020 %>% 
 filter(Users < 900) %>% 
 ggplot(aes(x = `Day Index`, y = Users)) +
 geom_line() + 
 geom_vline(xintercept = schema_date, color = "red") + 
 geom_smooth(method = "loess") +
 labs(
  title = "2020 daily visitors: Trend follows average visitor trend for this year", 
  x = "Date"
 ) + 
 theme_minimal()
```

```{r}
weekly_visitors %>% 
  drop_na() %>% 
  filter(`Week Index` != 43) %>% 
  filter(`Week Index` != 0) %>% 
  ggplot(aes(x = `Week Index`, y = Users, color = `Date Range`)) +
  geom_vline(aes(xintercept = schema_week)) +
  geom_smooth() + 
  geom_line() + 
  labs(
    title = "Visitor count decreases less drastically in 2020 after schema implementation", 
    subtitle = "However, 2019 and 2020 trends are too different to say for sure"
  ) + 
  theme_minimal()
```

## Duration
```{r}
new_engagement_duration_timeseries <-
 engagement_duration_timeseries %>% 
 mutate(
  `Session Duration` = fct_collapse(`Session Duration`, 
     `0 - 10 seconds` = c("0-10 seconds"), 
     `10 sec - 1 min` = c("11-30 seconds", "31-60 seconds"),
     `1 min - 10 min` = c("61-180 seconds", "181-600 seconds"), 
     `10 min - 30 min` = c("601-1800 seconds"), 
     `30+ min` = c("1801+ seconds")
   ), 
  `Session Duration` = fct_relevel(`Session Duration`, "0 - 10 seconds", "10 sec - 1 min", "1 min - 10 min", "10 min - 30 min", "30+ min")
 ) %>% 
 group_by(`Session Duration`, week_index) %>% 
 summarize(
  Sessions = sum(Sessions), 
  Pageviews = sum(Pageviews)
 ) %>% 
 ungroup() %>% 
 filter(`Session Duration` != "Total")

```

```{r}
new_engagement_duration_timeseries %>% 
  filter(`Session Duration` != "Total") %>% 
  ggplot(aes(x = week_index, y = Sessions, color = `Session Duration`)) + 
  geom_line() + 
  geom_vline(xintercept = 19) + 
  labs(
   title = "Session duration fairly stable over time", 
   subtitle = "Relatively many visitors stay on the website for 1 to 10 minutes",
   x = "Week Index"
  ) +
  theme_minimal() 
```


```{r}
new_engagement_duration_timeseries %>% 
  mutate(
    pageview_per_session = Pageviews / Sessions
  ) %>% 
  filter(`Session Duration` != "Total") %>% 
  ggplot(aes(x = week_index, y = pageview_per_session, color = `Session Duration`)) + 
  geom_line() + 
  geom_vline(xintercept = 18) + 
  labs(
   title = "Pageview per session increases drastically after schema implementation", 
   subtitle = "May indicate that website is finding significantly more engaged users",
   x = "Week Index", 
   y = "Pageview per session"
  ) +
  theme_minimal()
```

## Search Result Performance

```{r}
search_result_performance %>% 
  ggplot(aes(x = Date)) + 
  geom_line(aes(y = CTR)) + 
  geom_smooth(aes(y = CTR)) + 
  geom_vline(aes(xintercept = schema_date), color = "red") + 
  theme_minimal()
```


```{r}
search_result_performance %>% 
  ggplot(aes(x = Date, y = `Average Position`)) + 
  geom_line() + 
  geom_smooth() + 
  geom_vline(aes(xintercept = schema_date), color = "red") + 
  scale_y_reverse() + 
  theme_minimal()
```

```{r}
search_result_performance %>% 
  drop_na() %>% 
  ggplot(aes(x = Date, y = `Impressions`)) + 
  geom_line() + 
  geom_smooth() + 
  geom_vline(aes(xintercept = schema_date), color = "red") + 
  theme_minimal()
```

```{r}
search_result_performance %>% 
  drop_na() %>% 
  ggplot(aes(x = Date, y = `Clicks`)) + 
  geom_line() + 
  geom_smooth() + 
  geom_vline(aes(xintercept = schema_date), color = "red") + 
  theme_minimal()
```
